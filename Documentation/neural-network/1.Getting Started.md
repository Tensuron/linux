# Getting Started with Kernel Neural Networks

This guide provides a comprehensive introduction to using the Linux kernel neural network implementation for AI-powered security systems.

## Overview

The kernel neural network module provides high-performance, secure neural network inference capabilities directly in kernel space. It's designed for real-time malware detection and other security applications that require low-latency AI processing.

## Key Features

- **Kernel-space execution**: No userspace dependencies
- **SIMD optimization**: Vectorized operations for improved performance
- **NUMA awareness**: Optimized memory allocation for multi-socket systems
- **Prediction caching**: Intelligent caching to reduce computation overhead
- **Thread safety**: Full synchronization for concurrent access
- **Security features**: Input validation, integrity checks, and secure mode
- **DebugFS interface**: Runtime monitoring and configuration

## Quick Start

### 1. Basic Usage Example

```c
#include <linux/neural.h>

static neural_network_t *nn;

static int __init my_module_init(void)
{
    int ret;
    s32 input[4] = {INT_TO_FIXED(1), INT_TO_FIXED(2), 
                    INT_TO_FIXED(3), INT_TO_FIXED(4)};
    s32 output[2];
    
    // Initialize neural network (4 inputs, 8 hidden, 2 outputs)
    nn = neural_network_init(4, 8, 2);
    if (IS_ERR(nn)) {
        pr_err("Failed to initialize neural network: %ld\n", PTR_ERR(nn));
        return PTR_ERR(nn);
    }
    
    // Perform prediction
    ret = neural_network_predict(nn, input, output, 4, 2);
    if (ret < 0) {
        pr_err("Prediction failed: %d\n", ret);
        goto cleanup;
    }
    
    pr_info("Prediction result: %d, %d\n", 
            FIXED_TO_INT(output[0]), FIXED_TO_INT(output[1]));
    
    return 0;

cleanup:
    neural_network_cleanup(nn);
    return ret;
}

static void __exit my_module_exit(void)
{
    if (nn)
        neural_network_cleanup(nn);
}

module_init(my_module_init);
module_exit(my_module_exit);
MODULE_LICENSE("GPL");
```

### NUMA Considerations

For optimal performance on NUMA systems:

```c
// Initialize with specific NUMA node
neural_network_t *nn = neural_network_init_numa(4, 8, 2, 0);

// Check current NUMA node
int node = neural_get_numa_node(nn);

// Set CPU affinity for predictions
cpumask_t mask;
cpumask_clear(&mask);
cpumask_set_cpu(0, &mask);
neural_set_cpu_affinity(nn, &mask);
```

## Performance Optimization

### Batch Processing

Process multiple inputs efficiently:

```c
neural_batch_t *batch = neural_batch_create(nn, 10);
if (!IS_ERR(batch)) {
    // Add inputs to batch
    for (int i = 0; i < 10; i++) {
        neural_batch_add_input(batch, inputs[i], 4);
    }
    
    // Process entire batch
    ret = neural_batch_predict(batch, outputs);
    
    neural_batch_destroy(batch);
}
```

### Prediction Caching

Enable caching for repeated inputs:

```c
// Use cached prediction (automatically managed)
ret = neural_network_predict_cached(nn, input, output, 4, 2);

// Configure cache timeout
neural_set_cache_timeout(nn, 1000); // 1 second
```

## Security Features

### Input Validation

All inputs are automatically validated:

```c
// This will fail with -EINVAL if input is invalid
ret = neural_network_predict(nn, NULL, output, 4, 2);

// Check validation result
if (ret == -EINVAL) {
    pr_err("Invalid input parameters\n");
}
```

### Secure Mode

Enable enhanced security features:

```c
// Enable secure mode during initialization
neural_set_secure_mode(nn, true);

// All operations will include additional validation
ret = neural_network_predict(nn, input, output, 4, 2);
```

## Error Handling

### Common Error Codes

- `NEURAL_SUCCESS (0)`: Operation successful
- `NEURAL_ERROR_INVALID_PARAMS (-1)`: Invalid parameters
- `NEURAL_ERROR_OUT_OF_MEMORY (-2)`: Memory allocation failed
- `NEURAL_ERROR_NOT_INITIALIZED (-3)`: Network not initialized
- `NEURAL_ERROR_COMPUTATION_FAILED (-4)`: Computation error
- `NEURAL_ERROR_CACHE_MISS (-5)`: Cache miss occurred

### Error Recovery

```c
ret = neural_network_predict(nn, input, output, 4, 2);
switch (ret) {
case NEURAL_SUCCESS:
    // Process output
    break;
case NEURAL_ERROR_INVALID_PARAMS:
    pr_err("Invalid parameters provided\n");
    break;
case NEURAL_ERROR_OUT_OF_MEMORY:
    pr_err("Out of memory, try reducing batch size\n");
    break;
case NEURAL_ERROR_COMPUTATION_FAILED:
    pr_err("Computation failed, check network integrity\n");
    // Attempt recovery
    neural_network_reset(nn);
    break;
default:
    pr_err("Unexpected error: %d\n", ret);
}
```

## Debugging and Monitoring

### Kernel Logging

Enable debug logging:

```bash
# Set log level for neural network
echo 8 > /proc/sys/kernel/printk
dmesg | grep neural
```

### Statistics Monitoring

```c
neural_stats_t stats;
neural_get_statistics(nn, &stats);

pr_info("Predictions: %llu, Cache hits: %llu, Errors: %llu\n",
        stats.total_predictions, stats.cache_hits, stats.total_errors);
```

## Next Steps

- Review [Data Structures](4.Data%20Structures.md) for detailed API reference
- Check [Performance Tuning](7.Performance%20Tuning.md) for optimization tips
- See [Security Features](8.Security%20Features.md) for security configuration

## Troubleshooting

### Common Issues

1. **Module fails to load**
   - Verify dependencies are met
   - Check dmesg for error messages

2. **Poor performance**
   - GPU/TPU/NPU Must Be Insalled On This Machine 
   - Enable SIMD optimizations
   - Configure NUMA settings
   - Use batch processing for multiple inputs

3. **Memory allocation failures**
   - Reduce network size or batch size
   - Check available memory
   - Consider NUMA node allocation

4. **Prediction errors**
   - Validate input data format
   - Check network initialization
   - Verify weight integrity

For more detailed troubleshooting, see [Debugging and Monitoring](9.Debugging%20and%20Monitoring.md).
# Debugging and Monitoring

## Overview
The neural network implementation provides comprehensive debugging and monitoring capabilities through DebugFS interface, kernel logging, and performance statistics.

## DebugFS Interface

### Directory Structure
```
/sys/kernel/debug/neural_network/
├── network_0/
│   ├── stats
│   ├── config
│   ├── layers/
│   │   ├── layer_0
│   │   ├── layer_1
│   │   └── ...
│   └── cache_info
├── network_1/
└── ...
```

### Statistics Interface
```bash
# View comprehensive network statistics
cat /sys/kernel/debug/neural_network/network_0/stats
```

Output format:
```
Neural Network Statistics:
Predictions: 15420
Total inference time: 7710000 ns
Average inference time: 500 μs
Cache hits: 12336
Cache misses: 3084
Cache hit rate: 80.0%
Errors encountered: 0
SIMD operations: 8760
NUMA allocations: 24
Security violations: 0
Peak memory usage: 2048 KB
Memory efficiency: 95.2%
Last prediction: 1640995200000000000 ns
```

### Configuration Interface
```bash
# Runtime configuration
echo "simd 1" > /sys/kernel/debug/neural_network/network_0/config
echo "cache_timeout 1000" > /sys/kernel/debug/neural_network/network_0/config
echo "numa_policy 1" > /sys/kernel/debug/neural_network/network_0/config
echo "debug_level 2" > /sys/kernel/debug/neural_network/network_0/config
```

### Layer Information
```bash
# View individual layer details
cat /sys/kernel/debug/neural_network/network_0/layers/layer_0
```

Output:
```
Layer 0 Information:
Input size: 256
Output size: 128
Activation type: 0 (ReLU)
Weights validated: yes
Checksum: 0x12345678
NUMA node: 1
SIMD enabled: yes
Computation count: 15420
Last access: 1640995200000000000 ns
Memory usage: 131072 bytes
```

## Kernel Logging

### Log Levels
The neural network uses standard kernel log levels:

```c
pr_emerg("Neural: Emergency condition\n");      // System unusable
pr_alert("Neural: Alert condition\n");          // Action must be taken
pr_crit("Neural: Critical condition\n");        // Critical conditions
pr_err("Neural: Error condition\n");            // Error conditions
pr_warn("Neural: Warning condition\n");         // Warning conditions
pr_notice("Neural: Normal but significant\n");  // Normal but significant
pr_info("Neural: Informational\n");             // Informational
pr_debug("Neural: Debug message\n");            // Debug-level messages
```

### Debug Logging
```c
#ifdef NEURAL_DEBUG
#define neural_debug(fmt, ...) \
    pr_debug("Neural[%s:%d]: " fmt, __func__, __LINE__, ##__VA_ARGS__)
#else
#define neural_debug(fmt, ...) do { } while (0)
#endif
```

### Error Logging
```c
static void neural_log_error(neural_network_t *nn, int error_code, 
                           const char *function, int line) {
    const char *error_msg;
    
    switch (error_code) {
    case NEURAL_ERROR_INVALID_INPUT:
        error_msg = "Invalid input parameters";
        break;
    case NEURAL_ERROR_MEMORY:
        error_msg = "Memory allocation failure";
        break;
    case NEURAL_ERROR_SECURITY_VIOLATION:
        error_msg = "Security violation detected";
        break;
    default:
        error_msg = "Unknown error";
    }
    
    pr_err("Neural: %s in %s:%d (code: %d)\n", 
           error_msg, function, line, error_code);
    
    if (nn) {
        neural_record_error(nn, error_msg);
    }
}
```

## Performance Monitoring

### Real-Time Statistics
```c
// Update statistics atomically
static inline void neural_update_prediction_stats(neural_network_t *nn, 
                                                 ktime_t start_time) {
    ktime_t end_time = ktime_get();
    s64 inference_time_ns = ktime_to_ns(ktime_sub(end_time, start_time));
    
    atomic64_inc(&nn->stats.predictions_made);
    atomic64_add(inference_time_ns, &nn->stats.total_inference_time_ns);
    
    // Update average (lockless)
    u64 total_predictions = atomic64_read(&nn->stats.predictions_made);
    if (total_predictions > 0) {
        nn->stats.avg_inference_time_us = (u32)(
            atomic64_read(&nn->stats.total_inference_time_ns) / 
            (total_predictions * 1000)
        );
    }
}
```

### Performance Profiling
```c
typedef struct neural_profiler {
    ktime_t start_time;
    ktime_t end_time;
    u64 cycles_start;
    u64 cycles_end;
    u32 cache_misses;
    u32 branch_misses;
    bool active;
} neural_profiler_t;

static inline void neural_profiler_start(neural_profiler_t *prof) {
    prof->start_time = ktime_get();
    prof->cycles_start = get_cycles();
    prof->active = true;
}

static inline void neural_profiler_end(neural_profiler_t *prof) {
    if (!prof->active) return;
    
    prof->end_time = ktime_get();
    prof->cycles_end = get_cycles();
    prof->active = false;
}
```

### Memory Usage Tracking
```c
static void neural_track_memory_usage(neural_network_t *nn) {
    size_t current_usage = 0;
    
    for (u32 i = 0; i < nn->num_layers; i++) {
        current_usage += neural_calculate_layer_memory(&nn->layers[i]);
    }
    
    nn->total_memory_usage = current_usage;
    
    if (current_usage > nn->stats.peak_memory_usage_kb * 1024) {
        nn->stats.peak_memory_usage_kb = current_usage / 1024;
    }
}
```

## Error Detection and Reporting

### Self-Test Framework
```c
static int neural_self_test(neural_network_t *nn) {
    s32 test_input[16] = {0};
    s32 test_output[8];
    int ret = 0;
    
    if (!nn || !nn->initialized)
        return -EINVAL;
    
    // Basic connectivity test
    for (int i = 0; i < min(16U, nn->INPUT_LAYER); i++) {
        test_input[i] = INT_TO_FP(1);
    }
    
    ret = neural_network_predict(nn, test_input, test_output);
    if (ret) {
        neural_record_error(nn, "Self-test prediction failed");
        return ret;
    }
    
    // Validate layer checksums
    for (u32 i = 0; i < nn->num_layers; i++) {
        neural_layer_t *layer = &nn->layers[i];
        u32 checksum = crc32(0, (u8*)layer->weights, 
                            layer->weights_size * sizeof(s32));
        if (checksum != layer->checksum) {
            neural_record_error(nn, "Layer checksum mismatch");
            return -NEURAL_ERROR_SECURITY_VIOLATION;
        }
    }
    
    pr_info("Neural: Self-test completed successfully\n");
    return 0;
}
```

### Integrity Verification
```c
static bool neural_verify_network_integrity(neural_network_t *nn) {
    if (!nn || !nn->initialized)
        return false;
    
    // Check magic numbers and basic structure
    if (nn->num_layers == 0 || nn->num_layers > NEURAL_MAX_LAYERS)
        return false;
    
    // Verify each layer
    for (u32 i = 0; i < nn->num_layers; i++) {
        if (!neural_verify_layer_integrity(&nn->layers[i]))
            return false;
    }
    
    return true;
}
```

## Diagnostic Tools

### Network State Dump
```c
static void neural_dump_network_state(neural_network_t *nn) {
    if (!nn) return;
    
    pr_info("Neural Network State Dump:\n");
    pr_info("  Initialized: %s\n", nn->initialized ? "yes" : "no");
    pr_info("  Layers: %u\n", nn->num_layers);
    pr_info("  Input size: %u\n", nn->INPUT_LAYER);
    pr_info("  Hidden size: %u\n", nn->HIDDEN_LAYER);
    pr_info("  Output size: %u\n", nn->OUTPUT_LAYER);
    pr_info("  Training mode: %s\n", nn->training_mode ? "yes" : "no");
    pr_info("  Secure mode: %s\n", nn->secure_mode ? "yes" : "no");
    pr_info("  Total memory: %zu bytes\n", nn->total_memory_usage);
    pr_info("  NUMA node: %d\n", nn->preferred_numa_node);
    
    for (u32 i = 0; i < nn->num_layers; i++) {
        neural_layer_t *layer = &nn->layers[i];
        pr_info("  Layer %u: %ux%u, activation=%u, NUMA=%d\n",
                i, layer->input_size, layer->output_size,
                layer->activation_type, layer->numa_node);
    }
}
```

### Cache Analysis
```c
static void neural_analyze_cache_performance(neural_network_t *nn) {
    u64 hits = atomic64_read(&nn->stats.cache_hits);
    u64 misses = atomic64_read(&nn->stats.cache_misses);
    u64 total = hits + misses;
    
    if (total == 0) {
        pr_info("Neural: No cache activity\n");
        return;
    }
    
    u32 hit_rate = (u32)((hits * 100) / total);
    
    pr_info("Neural Cache Analysis:\n");
    pr_info("  Cache hits: %llu\n", hits);
    pr_info("  Cache misses: %llu\n", misses);
    pr_info("  Hit rate: %u%%\n", hit_rate);
    pr_info("  Cache timeout: %llu ns\n", nn->prediction_cache.timeout_ns);
    
    if (hit_rate < 50) {
        pr_warn("Neural: Low cache hit rate, consider tuning timeout\n");
    }
}
```

## Troubleshooting Guide

### Common Issues and Solutions

#### High Memory Usage
```bash
# Check memory statistics
cat /sys/kernel/debug/neural_network/network_*/stats | grep memory

# Solutions:
# 1. Reduce network size
# 2. Enable memory compression
# 3. Use smaller batch sizes
```

#### Poor Performance
```bash
# Check SIMD usage
cat /sys/kernel/debug/neural_network/network_*/stats | grep simd

# Enable SIMD if not active
echo 1 > /sys/module/neural/parameters/neural_enable_simd

# Check NUMA allocation
numastat -p $(pgrep neural)
```

#### Cache Inefficiency
```bash
# Monitor cache hit rate
watch -n 1 'cat /sys/kernel/debug/neural_network/network_*/stats | grep cache'

# Tune cache timeout
echo "cache_timeout 2000" > /sys/kernel/debug/neural_network/network_*/config
```

### Debug Commands
```bash
# Enable debug logging
echo 8 > /proc/sys/kernel/printk

# Monitor kernel messages
dmesg -w | grep Neural

# Check module parameters
cat /sys/module/neural/parameters/*

# Verify module loading
lsmod | grep neural
modinfo neural
```

### Performance Analysis
```bash
# Use perf for detailed profiling
perf record -g -p $(pgrep neural_test)
perf report

# Monitor system calls
strace -p $(pgrep neural_test)

# Check CPU usage
top -p $(pgrep neural_test)

# Monitor memory allocation
cat /proc/$(pgrep neural_test)/status | grep Vm
```

## Automated Monitoring

### Health Check Script
```bash
#!/bin/bash
# neural_health_check.sh

NEURAL_DEBUG_PATH="/sys/kernel/debug/neural_network"

for network in $NEURAL_DEBUG_PATH/network_*; do
    if [ -d "$network" ]; then
        echo "Checking $(basename $network)..."
        
        # Check error count
        errors=$(grep "Errors encountered:" $network/stats | awk '{print $3}')
        if [ "$errors" -gt 0 ]; then
            echo "WARNING: $errors errors detected"
        fi
        
        # Check cache hit rate
        hits=$(grep "Cache hits:" $network/stats | awk '{print $3}')
        misses=$(grep "Cache misses:" $network/stats | awk '{print $3}')
        if [ "$hits" -gt 0 ] && [ "$misses" -gt 0 ]; then
            hit_rate=$((hits * 100 / (hits + misses)))
            if [ "$hit_rate" -lt 70 ]; then
                echo "WARNING: Low cache hit rate: $hit_rate%"
            fi
        fi
        
        # Check memory usage
        memory=$(grep "Peak memory usage:" $network/stats | awk '{print $4}')
        if [ "$memory" -gt 10240 ]; then  # 10MB threshold
            echo "WARNING: High memory usage: ${memory}KB"
        fi
    fi
done
```

### Continuous Monitoring
```bash
# Set up monitoring with systemd timer
cat > /etc/systemd/system/neural-monitor.service << EOF
[Unit]
Description=Neural Network Health Monitor
After=multi-user.target

[Service]
Type=oneshot
ExecStart=/usr/local/bin/neural_health_check.sh
User=root
EOF

cat > /etc/systemd/system/neural-monitor.timer << EOF
[Unit]
Description=Run neural health check every 5 minutes
Requires=neural-monitor.service

[Timer]
OnCalendar=*:0/5
Persistent=true

[Install]
WantedBy=timers.target
EOF

systemctl enable neural-monitor.timer
systemctl start neural-monitor.timer
```

# Data Structures

## Overview
This document describes all data structures and types defined in `linux/neural.h`.

## Core Data Structures

### neural_network_t
The main neural network structure containing all network state and configuration.

```c
typedef struct {
    u32 INPUT_LAYER;                /* Number of input neurons */
    u32 HIDDEN_LAYER;               /* Number of hidden neurons */
    u32 OUTPUT_LAYER;               /* Number of output neurons */
    u32 num_layers;                 /* Total number of layers */
    neural_layer_t *layers;         /* Array of network layers */
    
    /* Synchronization */
    spinlock_t lock;                /* Coarse-grained lock for whole network */
    struct mutex training_mutex;    /* For training operations */
    atomic_t refcount;              /* Reference counting */
    struct completion ready;        /* For async operations */
    struct rw_semaphore config_sem; /* Configuration changes */
    
    /* State management */
    bool initialized;               /* Network initialization status */
    bool training_mode;             /* Training mode flag */
    u32 epoch_count;               /* Training epoch counter */
    u32 flags;                     /* Runtime flags */
    
    /* Performance monitoring */
    neural_stats_t stats;          /* Performance statistics */
    ktime_t last_prediction_time;  /* Last prediction timestamp */
    
    /* Memory management with NUMA awareness */
    size_t total_memory_usage;     /* Total memory allocated */
    u32 max_batch_size;           /* Maximum batch size */
    struct kmem_cache *cache;      /* Slab cache for allocations */
    int preferred_numa_node;       /* Preferred NUMA node */
    cpumask_t allowed_cpus;        /* CPUs allowed for computation */
    
    /* Advanced features */
    s32 learning_rate;             /* Learning rate in fixed-point */
    s32 momentum;                  /* Momentum factor */
    s32 weight_decay;              /* Weight decay factor */
    bool use_batch_norm;           /* Batch normalization enabled */
    bool adaptive_learning;        /* Adaptive learning rate */
    
    /* Security features */
    u64 creation_time;             /* Network creation timestamp */
    u32 security_token;            /* Security validation token */
    bool secure_mode;              /* Enhanced security checks */
    
    /* Prediction cache */
    struct {
        u32 input_hash;            /* Hash of cached input */
        s32 *cached_output;        /* Cached output values */
        ktime_t cache_time;        /* Cache timestamp */
        bool valid;                /* Cache validity flag */
        u32 output_size;           /* Size of cached output */
        spinlock_t lock;           /* Cache-specific lock */
        atomic_t hit_count;        /* Cache hit counter */
        u64 timeout_ns;            /* Cache timeout in nanoseconds */
    } prediction_cache;
    
    /* Debug and profiling */
    struct dentry *debug_dir;      /* DebugFS directory */
    bool profiling_enabled;        /* Performance profiling */
    struct {
        u64 forward_pass_time;     /* Forward pass timing */
        u64 activation_time;       /* Activation function timing */
        u64 memory_access_time;    /* Memory access timing */
        u32 cache_efficiency;      /* Cache efficiency percentage */
    } profiling_data;
} neural_network_t;
```

### neural_layer_t
Individual layer structure with NUMA and performance optimizations.

```c
typedef struct neural_layer {
    s32 *weights NEURAL_ALIGN;      /* Fixed-point weights matrix */
    s32 *biases NEURAL_ALIGN;       /* Fixed-point bias vector */
    s32 *neurons NEURAL_ALIGN;      /* Neuron outputs */
    s32 *gradients NEURAL_ALIGN;    /* Gradients for training */
    s32 *weight_momentum NEURAL_ALIGN; /* Momentum for optimization */
    u32 input_size;                 /* Number of inputs */
    u32 output_size;                /* Number of outputs */
    u8 activation_type;             /* Activation function type */
    u8 padding[3];                  /* Padding for alignment */
    f32 dropout_rate;               /* Dropout probability */
    bool batch_norm;                /* Batch normalization enabled */
    s32 *bn_gamma NEURAL_ALIGN;     /* Batch norm scale parameters */
    s32 *bn_beta NEURAL_ALIGN;      /* Batch norm shift parameters */
    u32 weights_size;               /* Size of weights array */
    u32 biases_size;                /* Size of biases array */
    rwlock_t lock;                  /* Read-write lock for thread safety */
    
    /* NUMA and performance optimization */
    int numa_node;                  /* NUMA node for this layer */
    bool use_simd;                  /* Enable SIMD for this layer */
    u64 computation_count;          /* Number of computations performed */
    ktime_t last_access_time;       /* Last access timestamp */
    
    /* Security and validation */
    u32 checksum;                   /* CRC32 checksum of weights */
    bool weights_validated;         /* Weights have been validated */
} neural_layer_t;
```

### neural_stats_t
Performance statistics with per-CPU counters.

```c
typedef struct neural_stats {
    atomic64_t predictions_made;        /* Total predictions */
    atomic64_t total_inference_time_ns; /* Total inference time */
    atomic64_t cache_hits;              /* Cache hit count */
    atomic64_t cache_misses;            /* Cache miss count */
    atomic64_t errors_encountered;      /* Error count */
    atomic64_t simd_operations;         /* SIMD operation count */
    atomic64_t numa_allocations;        /* NUMA allocation count */
    atomic64_t security_violations;     /* Security violation count */
    u32 avg_inference_time_us;          /* Average inference time */
    u32 peak_memory_usage_kb;           /* Peak memory usage */
    u32 min_batch_time_us;              /* Minimum batch time */
    u32 max_batch_time_us;              /* Maximum batch time */
    u64 last_error_ts;                  /* Timestamp of last error */
    char last_error[128];               /* Description of last error */
    
    /* Per-CPU statistics */
    struct {
        u64 predictions;                /* Per-CPU prediction count */
        u64 cache_hits;                 /* Per-CPU cache hits */
        u64 errors;                     /* Per-CPU error count */
    } __percpu *per_cpu_stats;
} neural_stats_t __aligned(NEURAL_CACHE_LINE_SIZE);
```

## Auxiliary Structures

### neural_batch_t
Batch processing structure for multiple samples.

```c
typedef struct neural_batch {
    s32 **inputs;           /* Array of input vectors */
    s32 **outputs;          /* Array of output vectors */
    u32 batch_size;         /* Number of samples in batch */
    u32 input_dim;          /* Input dimensionality */
    u32 output_dim;         /* Output dimensionality */
} neural_batch_t;
```

### neural_model_header_t
Model serialization header for saving/loading networks.

```c
typedef struct neural_model_header {
    u32 magic;              /* Magic number for validation */
    u32 version;            /* Model format version */
    u32 num_layers;         /* Number of layers */
    u32 total_weights;      /* Total weight count */
    u32 checksum;           /* CRC32 checksum */
    u64 timestamp;          /* Creation timestamp */
} neural_model_header_t;
```

### neural_adaptive_lr_t
Adaptive learning rate structure.

```c
typedef struct {
    s32 base_rate;                  /* Base learning rate */
    s32 decay_factor;               /* Decay factor */
    s32 min_rate;                   /* Minimum learning rate */
    s32 max_rate;                   /* Maximum learning rate */
    u32 patience;                   /* Patience for rate adjustment */
    u32 steps_without_improvement;  /* Steps without improvement */
    s32 best_loss;                  /* Best loss seen so far */
    bool enabled;                   /* Adaptive learning enabled */
} neural_adaptive_lr_t;
```

### neural_profiler_t
Performance profiler structure.

```c
typedef struct {
    ktime_t start_time;     /* Profiling start time */
    ktime_t end_time;       /* Profiling end time */
    u64 cycles_start;       /* CPU cycles at start */
    u64 cycles_end;         /* CPU cycles at end */
    u32 cache_misses;       /* Cache miss count */
    u32 branch_misses;      /* Branch miss count */
    bool active;            /* Profiler active flag */
} neural_profiler_t;
```

## Type Definitions

### Forward Declarations
```c
typedef struct neural_network NeuralNetwork;  /* Legacy compatibility */
```

## Activation Function Types

The `activation_type` field in `neural_layer_t` uses these values:

| Value | Function | Description |
|-------|----------|-------------|
| 0 | ReLU | Rectified Linear Unit: max(0, x) |
| 1 | Sigmoid | Sigmoid function: 1/(1+e^-x) |
| 2 | Linear | Linear activation: f(x) = x |
| 3 | Tanh | Hyperbolic tangent: tanh(x) |
| 4 | Leaky ReLU | Leaky ReLU: max(0.01x, x) |

## Memory Alignment

All critical data structures use cache-line alignment (`NEURAL_ALIGN`) for optimal performance:
- Weight matrices
- Bias vectors  
- Neuron outputs
- Gradient arrays
- Batch normalization parameters

## Thread Safety

The structures provide multiple levels of synchronization:
- **Coarse-grained**: `spinlock_t lock` for entire network
- **Fine-grained**: `rwlock_t lock` per layer
- **Cache-specific**: `spinlock_t lock` for prediction cache
- **Configuration**: `rw_semaphore config_sem` for configuration changes
- **Training**: `mutex training_mutex` for training operations

## NUMA Considerations

Structures support NUMA-aware allocation:
- `preferred_numa_node`: Preferred NUMA node for allocation
- `allowed_cpus`: CPU mask for computation affinity
- `numa_node`: Per-layer NUMA node assignment
